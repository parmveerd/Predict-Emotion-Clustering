{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Visualizing Unlabeled Training Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "relative_path = \"faces/faces_AU.csv\" # Change this path if you need to\n",
    "data = pd.read_csv(relative_path)\n",
    "\n",
    "\n",
    "selected_features = data[[' gaze_0_x', ' gaze_0_y', ' gaze_0_z', ' gaze_1_x', ' gaze_1_y', ' gaze_1_z',\n",
    "                          ' gaze_angle_x', ' gaze_angle_y',\n",
    "                          ' AU05_r', ' AU06_r', ' AU07_r']]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(selected_features)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Plot data points in 2D\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], alpha=0.5)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Faces Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display explained variance for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance for each component:\", explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing the features, we used PCA to plot the data points in 2 dimensions. The results of the plot are shown above with the explained variance for each component.\n",
    "\n",
    "PCA was used to dimensionally reduce the data by transforming it into a new coordinate system. The first principal component finds the direction of the maximum variance and the second component finds the direction of the maximum remaining variance. Our plot shows most of our data is cluttered in one area, as expected.\n",
    "\n",
    "The explained variance ratio of the principal component represents the proportion of the dataset's variance that lies along the axis of that component. In other words, it shows how much variance is captured by each component. As shown above, the explained variance for our two components is 0.301 and 0.251.  This means that the first component explains about 30.1% of the total variance in the dataset and the second component explains 25.1% of the total variance. In total, our two components explain 30.1+25.1=55.2% of the total variance.\n",
    "\n",
    "Our two components together capture a big portion of the total variance in our data, making them useful for reducing the dimensionality of our data, while retaining information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. K-Means and Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to store silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Define range of K values\n",
    "k_values = range(2, 11)\n",
    "\n",
    "# Iterate over each K value\n",
    "for k in k_values:\n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "    clusters = kmeans.fit_predict(principal_components)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(principal_components, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores for different K values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal K and its corresponding silhouette score\n",
    "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "optimal_score = max(silhouette_scores)\n",
    "\n",
    "print(\"Optimal number of clusters (K):\", optimal_k)\n",
    "print(\"Optimal silhouette score:\", optimal_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the plot above, the optimal silhouette score is 0.368, and it represents a k value (number of clusters) of 3.\n",
    "\n",
    "The total silhouette score range is from -1 to 1, and our optimal score is 0.368, indicating a moderate score. This suggests our clusters are fairly well-separated but some overlapping is expected between our clusters. Looking at the plot, this is the best score as increasing the number of clusters would decrease our score and provide a worse result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Cluster Interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose the optimal K from Part 2\n",
    "k = optimal_k\n",
    "\n",
    "# Perform K-Means clustering with the optimal K\n",
    "kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "clusters = kmeans.fit_predict(principal_components)\n",
    "\n",
    "# Plot data points with colors representing clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster_id in range(k):\n",
    "    cluster_data = principal_components[clusters == cluster_id]\n",
    "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {cluster_id}')\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title(f'K-Means Clustering with K={k}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold image numbers for each cluster\n",
    "cluster_images = {cluster_id: [] for cluster_id in range(k)}\n",
    "\n",
    "# Populate the dictionary with image numbers\n",
    "for idx, cluster_id in enumerate(clusters):\n",
    "    image_number = data.iloc[idx]['img']\n",
    "    cluster_images[cluster_id].append(image_number)\n",
    "\n",
    "# Print the image numbers for each cluster\n",
    "for cluster_id, images in cluster_images.items():\n",
    "    print(f'Cluster {cluster_id}: {images}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the k-means plot above, our PCA-reduced data has been seperated into our optimal k (3) clusters, labeled cluster 0, 1, and 2. Then a dictionary was created to map each image with the correct cluster it was in. The results are printed above. Finally, I selected random images from each cluster to look for similarities within each cluster, so I can label them correctly.\n",
    "\n",
    "Also, we will be mostly looking at the eyes and cheeks because the selected features were gaze, AU5 (upper eyelid), AU6 (cheeks) and AU7 (eyelid tightner).\n",
    "\n",
    "The first thing I noticed was in Cluster 2, most people were smiling which made their cheeks rise (AU7) and they were looking directly into the camera. For Cluster 0, the cheeks were not raised, eyelids were not tightened, and upper eyelids were raised, which made most people look a little sad. Most faces were also looking into the camera. Finally for Cluster 1, the lids were tightened but the cheeks were lowered, and most people were not looking directly into the camera. So to label these, we could call Cluster 0: lowered cheeks and upper eyelids raised, Cluster 1: looking away, and Cluster 2: cheeks raised.\n",
    "\n",
    "It is worth mentioning that these labels are not perfect because based on our silhouette scores, we know there is overlapping between our clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Use UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction with UMAP\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_embeddings = umap_reducer.fit_transform(features_scaled)\n",
    "\n",
    "# Loop Over Different Numbers of Clusters\n",
    "best_score = -1\n",
    "best_k = -1\n",
    "for k in range(2, 11):\n",
    "    kmeans_umap = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    umap_clusters = kmeans_umap.fit_predict(umap_embeddings)\n",
    "    \n",
    "    # Compute Silhouette Score\n",
    "    silhouette_avg = silhouette_score(umap_embeddings, umap_clusters)\n",
    "    \n",
    "    # Choose Optimal Number of Clusters\n",
    "    if silhouette_avg > best_score:\n",
    "        best_score = silhouette_avg\n",
    "        best_k = k\n",
    "\n",
    "print(\"Optimal number of clusters:\", best_k)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(n_components=2, random_state=42).fit_transform(features_scaled)\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=kmeans.labels_, s=0.1, cmap='Spectral')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Define range of K values\n",
    "k_values = range(2, 11)\n",
    "\n",
    "# Iterate over each K value\n",
    "for k in k_values:\n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "    clusters_umap = kmeans.fit_predict(umap_embeddings)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(umap_embeddings, clusters_umap)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores for different K values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal K and its corresponding silhouette score\n",
    "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "optimal_score = max(silhouette_scores)\n",
    "\n",
    "print(\"Optimal number of clusters (K):\", optimal_k)\n",
    "print(\"Optimal silhouette score:\", optimal_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimal K from Part 2\n",
    "k = best_k\n",
    "\n",
    "# Perform K-Means clustering with the optimal K\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters_umap = kmeans.fit_predict(umap_embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster_id in range(k):\n",
    "    cluster_data = umap_embeddings[clusters_umap == cluster_id]\n",
    "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1])\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.title('UMAP with K-Means Clustering')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold image numbers for each cluster\n",
    "cluster_images = {cluster_id: [] for cluster_id in range(k)}\n",
    "\n",
    "# Populate the dictionary with image numbers\n",
    "for idx, cluster_id in enumerate(clusters_umap):\n",
    "    image_number = data.iloc[idx]['img']\n",
    "    cluster_images[cluster_id].append(image_number)\n",
    "\n",
    "# Print the image numbers for each cluster\n",
    "for cluster_id, images in cluster_images.items():\n",
    "    print(f'Cluster {cluster_id}: {images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, UMAP found the same number of clusters as PCA (3). However, the optimal silhouette score was higher than in step 2, as in this step it is 0.484. Looking at the k-means plot, we can see the data points are much more spread out compared to in the previous step.\n",
    "\n",
    "The results from our two steps are very similar as they both have three clusters and show similar shared expressions within the clusters.\n",
    "\n",
    "Overall, we observe that cluster 0 has lowered cheeks and upper eyelids raised, while cluster 1 is looking away with cheeks lowered and eyelids tightened, and cluster 2 has cheeks raised, while directly looking into the camera. People in cluster 2 seem the happiest, while in cluster 0 a lot of people look sad, and in cluster 1 people are mostly indifferent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
